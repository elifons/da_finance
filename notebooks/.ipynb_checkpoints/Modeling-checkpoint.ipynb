{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "473d4eae-d81f-4899-920c-007b63367c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import os.path as op\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "import yaml\n",
    "import shutil\n",
    "\n",
    "import tsaug as ts\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from utils.train_utils import evaluate_model, epoch_trainer, epoch_validation\n",
    "from utils.models import LSTMNet\n",
    "from utils.pytorchtools import EarlyStopping\n",
    "from utils.mySummary import SummaryLogger\n",
    "from utils.augmentation import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dd782bd-9487-44ea-96bd-343296d50638",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_path = os.path.dirname(os.getcwd()) # 'experiment directory'\n",
    "output_dir = run_path+'\\\\output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94fa4f49-5280-4931-9dea-7922aa40fafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_methods_mapping = {\n",
    "    'convolve': ts.Convolve(window=\"hann\"),\n",
    "    'pool': ts.Pool(size=3),\n",
    "    'jitter': ts.AddNoise(scale=0.05),\n",
    "    'quantize': ts.Quantize(n_levels=17),\n",
    "    'reverse': ts.Reverse(),\n",
    "    'timewarp': ts.TimeWarp(n_speed_change=4, max_speed_ratio=1.5),\n",
    "    'spawner': spawner,\n",
    "    'scaling': scaling,\n",
    "    'magnitude_warp': magnitude_warp,\n",
    "    'window_warp': window_warp\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62e524ef-9480-492f-b207-55c95af28cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.set_device(args.gpu_number)\n",
    "    print(torch.cuda.current_device())\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30ea2990-27c2-4df3-b5a9-582d4e4ccb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory(logdir):\n",
    "    try:\n",
    "        os.makedirs(logdir)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "create_directory(output_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3f8b547-4322-4e22-950e-f4ee41f61b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataloader(x_data, y_data, batch_size, shuffle=True):\n",
    "    train_data = TensorDataset(torch.from_numpy(x_data).float(), torch.from_numpy(y_data))\n",
    "    train_loader = DataLoader(train_data, shuffle=shuffle, batch_size=batch_size, drop_last=False)\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9572e82e-a1aa-4392-85b8-5a7a6c41a8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_dataset(i_sp, batch_size, da_method, augment_times=1):\n",
    "    data_dir = run_path + '\\\\data'\n",
    "    train_x = np.load(op.join(data_dir, 'study_period_X_'+str(i_sp)+'_train.npy'))\n",
    "    train_y = np.load(op.join(data_dir, 'study_period_Y_'+str(i_sp)+'_train.npy'))\n",
    "\n",
    "    validation_split = 0.2\n",
    "    dataset_size=train_x.shape[0]\n",
    "    indices = list(range(dataset_size))\n",
    "    split = dataset_size - int(np.floor(validation_split*dataset_size))\n",
    "\n",
    "    trainX, trainY = train_x[:split], train_y[:split]\n",
    "    if da_method in ['convolve', 'pool', 'jitter', 'quantize', 'reverse', 'timewarp']:\n",
    "        trainX = np.concatenate([trainX, *[da_methods_mapping[da_method].augment(trainX) for i in range(augment_times)]])\n",
    "        trainY = np.concatenate([trainY, *[trainY for i in range(augment_times)]])\n",
    "    elif da_method in ['magnitude_warp', 'window_warp', 'scaling']:\n",
    "        trainX = np.concatenate([trainX, *[da_methods_mapping[da_method](trainX) for i in range(augment_times)]])\n",
    "        trainY = np.concatenate([trainY, *[trainY for i in range(augment_times)]])\n",
    "    train_loader = build_dataloader(trainX, trainY, batch_size=batch_size)\n",
    "    valid_loader = build_dataloader(train_x[split:], train_y[split:], batch_size=batch_size)\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b96f772-a97a-470c-b041-22af313c718a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_single_model(model, train_loader, valid_loader, n_epochs, path, i_sp, device, patience):\n",
    "    logger = SummaryLogger(path)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True, path=path)\n",
    "    print('Start training')\n",
    "    for epoch in range(n_epochs):\n",
    "        counter = 0\n",
    "        loss, acc = epoch_trainer(model, train_loader, optimizer, criterion, logger, device)\n",
    "        valid_loss, valid_acc = epoch_validation(model, valid_loader, logger, device)\n",
    "        print(epoch, loss, acc, valid_loss, valid_acc)\n",
    "        early_stopping(valid_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break       \n",
    "    logger.close()\n",
    "    model_file_name = os.path.join(path, 'checkpoint.pt')\n",
    "    model.load_state_dict(torch.load(model_file_name))\n",
    "    metrics = evaluate_model(model, path, i_sp, device)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c0a393f-3b74-4dba-b53d-63502db4736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_for_all_study_periods(da_method,batch_size,hidden_dim,n_layers,n_epochs,init_sp,end_sp,patience):\n",
    "    for i in range(init_sp, end_sp+1):\n",
    "        path = op.join(run_path, 'output/study_period_'+str(i).zfill(2))\n",
    "        create_directory(path)\n",
    "        train_loader, valid_loader = augment_dataset(i, batch_size=batch_size, da_method=da_method)\n",
    "        model = LSTMNet(1, hidden_dim=hidden_dim, output_dim=2, n_layers=n_layers, device=device)\n",
    "        model.to(device)\n",
    "        metrics = train_eval_single_model(model, train_loader, valid_loader, n_epochs, path, i, device, patience)\n",
    "        print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a095d538-25a5-463a-943b-b3dbfe732797",
   "metadata": {},
   "source": [
    "#### Listing different augmentation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce48e5e6-c967-44c8-8ede-29f5db87b75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['convolve',\n",
       " 'pool',\n",
       " 'jitter',\n",
       " 'quantize',\n",
       " 'reverse',\n",
       " 'timewarp',\n",
       " 'spawner',\n",
       " 'scaling',\n",
       " 'magnitude_warp',\n",
       " 'window_warp',\n",
       " 'None']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da_method_list = list(da_methods_mapping.keys())+['None'] # 'augmentation methods'\n",
    "da_method_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b610eb3-a27d-476a-83a1-d60743580742",
   "metadata": {},
   "source": [
    "#### Method 1: Convolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5099f08-37e3-4dbb-8c94-7272d69d8505",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 # 'batch size'\n",
    "hidden_dim = 25 # 'hidden dimension of LSTM'\n",
    "n_layers = 1 # 'number of layers in the LSTM'\n",
    "n_epochs = 200 # 'number of epochs for training'\n",
    "init_sp = 0 # 'initial data split'\n",
    "end_sp = 29 # 'final data split'\n",
    "patience = 10 # 'patience for early stopping'\n",
    "da_method = 'convolve'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fb1dd7-066c-46a9-93c0-38958164940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_for_all_study_periods(da_method,batch_size,hidden_dim,n_layers,n_epochs,init_sp,end_sp,patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cc8cff-059f-4751-9910-faa754747518",
   "metadata": {},
   "source": [
    "#### Method 2: Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a227313a-c87f-45f7-a846-5ad84a02463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 # 'batch size'\n",
    "hidden_dim = 25 # 'hidden dimension of LSTM'\n",
    "n_layers = 1 # 'number of layers in the LSTM'\n",
    "n_epochs = 200 # 'number of epochs for training'\n",
    "init_sp = 0 # 'initial data split'\n",
    "end_sp = 29 # 'final data split'\n",
    "patience = 10 # 'patience for early stopping'\n",
    "da_method = 'pool'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c954d254-a14f-41bf-8f7d-2b1bbc2c5320",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_for_all_study_periods(da_method,batch_size,hidden_dim,n_layers,n_epochs,init_sp,end_sp,patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51de49d-289b-4a4a-b519-30b6c3228d68",
   "metadata": {},
   "source": [
    "#### Method 3: Jitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "040fcd3e-b6ba-4942-bc65-a2439911d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 # 'batch size'\n",
    "hidden_dim = 25 # 'hidden dimension of LSTM'\n",
    "n_layers = 1 # 'number of layers in the LSTM'\n",
    "n_epochs = 200 # 'number of epochs for training'\n",
    "init_sp = 0 # 'initial data split'\n",
    "end_sp = 29 # 'final data split'\n",
    "patience = 10 # 'patience for early stopping'\n",
    "da_method = 'jitter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198a528c-03f0-4b0e-847a-b7c0c0e8f95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_for_all_study_periods(da_method,batch_size,hidden_dim,n_layers,n_epochs,init_sp,end_sp,patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c60ae3-49f0-45df-ab7f-818c63dc2d6a",
   "metadata": {},
   "source": [
    "#### Method 4: Quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350e3e3c-2d9f-4225-81db-d9a300de77d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 # 'batch size'\n",
    "hidden_dim = 25 # 'hidden dimension of LSTM'\n",
    "n_layers = 1 # 'number of layers in the LSTM'\n",
    "n_epochs = 200 # 'number of epochs for training'\n",
    "init_sp = 0 # 'initial data split'\n",
    "end_sp = 29 # 'final data split'\n",
    "patience = 10 # 'patience for early stopping'\n",
    "da_method = 'quantize'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c41c396-c2c6-4436-a8fc-6400449f359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_for_all_study_periods(da_method,batch_size,hidden_dim,n_layers,n_epochs,init_sp,end_sp,patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c53094-a255-41a4-9bbe-7073badd1ce4",
   "metadata": {},
   "source": [
    "#### Method 5: Reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dc4977-7e43-417e-b13a-073e91e6c6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 # 'batch size'\n",
    "hidden_dim = 25 # 'hidden dimension of LSTM'\n",
    "n_layers = 1 # 'number of layers in the LSTM'\n",
    "n_epochs = 200 # 'number of epochs for training'\n",
    "init_sp = 0 # 'initial data split'\n",
    "end_sp = 29 # 'final data split'\n",
    "patience = 10 # 'patience for early stopping'\n",
    "da_method = 'reverse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eec6f1e-21b2-436f-9f57-b4619a909d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_for_all_study_periods(da_method,batch_size,hidden_dim,n_layers,n_epochs,init_sp,end_sp,patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e726bf-6e27-4926-bbea-c971702542ee",
   "metadata": {},
   "source": [
    "#### Method 6: Timewarp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93159769-2de7-4dd7-8e1d-a923464990dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 # 'batch size'\n",
    "hidden_dim = 25 # 'hidden dimension of LSTM'\n",
    "n_layers = 1 # 'number of layers in the LSTM'\n",
    "n_epochs = 200 # 'number of epochs for training'\n",
    "init_sp = 0 # 'initial data split'\n",
    "end_sp = 29 # 'final data split'\n",
    "patience = 10 # 'patience for early stopping'\n",
    "da_method = 'timewarp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef43f91-d79d-4ab6-9f62-341c98358eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_for_all_study_periods(da_method,batch_size,hidden_dim,n_layers,n_epochs,init_sp,end_sp,patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c805a933-ab88-4e0a-aa8f-f19aea11710c",
   "metadata": {},
   "source": [
    "#### Method 7: Spawner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67493fd-dc19-48d7-8470-becb240cd558",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 # 'batch size'\n",
    "hidden_dim = 25 # 'hidden dimension of LSTM'\n",
    "n_layers = 1 # 'number of layers in the LSTM'\n",
    "n_epochs = 200 # 'number of epochs for training'\n",
    "init_sp = 0 # 'initial data split'\n",
    "end_sp = 29 # 'final data split'\n",
    "patience = 10 # 'patience for early stopping'\n",
    "da_method = 'spawner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd76379-21b0-4e3e-a1d7-551914f2969c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_for_all_study_periods(da_method,batch_size,hidden_dim,n_layers,n_epochs,init_sp,end_sp,patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9c1461-f9c5-43f7-a07f-b5c1be08b78e",
   "metadata": {},
   "source": [
    "#### Method 8: scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c23a254-b817-4155-9011-78c8bac3925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 # 'batch size'\n",
    "hidden_dim = 25 # 'hidden dimension of LSTM'\n",
    "n_layers = 1 # 'number of layers in the LSTM'\n",
    "n_epochs = 200 # 'number of epochs for training'\n",
    "init_sp = 0 # 'initial data split'\n",
    "end_sp = 29 # 'final data split'\n",
    "patience = 10 # 'patience for early stopping'\n",
    "da_method = 'scaling'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48da2062-026c-4159-8bb6-ec0dd06dad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_for_all_study_periods(da_method,batch_size,hidden_dim,n_layers,n_epochs,init_sp,end_sp,patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e127ec0e-303d-4daa-94b1-fcc892c4db84",
   "metadata": {},
   "source": [
    "#### Method 9: magnitude_warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9d2b75-1310-4fa0-bb2e-36ee4752cdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 # 'batch size'\n",
    "hidden_dim = 25 # 'hidden dimension of LSTM'\n",
    "n_layers = 1 # 'number of layers in the LSTM'\n",
    "n_epochs = 200 # 'number of epochs for training'\n",
    "init_sp = 0 # 'initial data split'\n",
    "end_sp = 29 # 'final data split'\n",
    "patience = 10 # 'patience for early stopping'\n",
    "da_method = 'magnitude_warp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d425e8e-1984-450f-94a5-b044819beed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_for_all_study_periods(da_method,batch_size,hidden_dim,n_layers,n_epochs,init_sp,end_sp,patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b1d000-9c5c-47f7-bc18-fedca21019ca",
   "metadata": {},
   "source": [
    "#### Method 10: window_warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb1fe93-53ed-4ebc-96f2-7984bbe8a115",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 # 'batch size'\n",
    "hidden_dim = 25 # 'hidden dimension of LSTM'\n",
    "n_layers = 1 # 'number of layers in the LSTM'\n",
    "n_epochs = 200 # 'number of epochs for training'\n",
    "init_sp = 0 # 'initial data split'\n",
    "end_sp = 29 # 'final data split'\n",
    "patience = 10 # 'patience for early stopping'\n",
    "da_method = 'window_warp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d47a72-e4d5-4e3d-aafe-4622b396ef43",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_for_all_study_periods(da_method,batch_size,hidden_dim,n_layers,n_epochs,init_sp,end_sp,patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14aabb3-4d55-47e8-81a5-a279cc5c61af",
   "metadata": {},
   "source": [
    "#### Method 11: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff06c48-173a-4b4f-b4eb-8137a38ccb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 # 'batch size'\n",
    "hidden_dim = 25 # 'hidden dimension of LSTM'\n",
    "n_layers = 1 # 'number of layers in the LSTM'\n",
    "n_epochs = 200 # 'number of epochs for training'\n",
    "init_sp = 0 # 'initial data split'\n",
    "end_sp = 29 # 'final data split'\n",
    "patience = 10 # 'patience for early stopping'\n",
    "da_method = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b79e6a4-c31a-4edf-9d64-b5a34f0a09c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_for_all_study_periods(da_method,batch_size,hidden_dim,n_layers,n_epochs,init_sp,end_sp,patience)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
